{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Huggingface 이용한 문장 분류 프로젝트","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-09T11:40:58.601381Z","iopub.execute_input":"2023-07-09T11:40:58.601744Z","iopub.status.idle":"2023-07-09T11:40:58.612333Z","shell.execute_reply.started":"2023-07-09T11:40:58.601717Z","shell.execute_reply":"2023-07-09T11:40:58.611409Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:00.002090Z","iopub.execute_input":"2023-07-09T11:41:00.002456Z","iopub.status.idle":"2023-07-09T11:41:12.884361Z","shell.execute_reply.started":"2023-07-09T11:41:00.002427Z","shell.execute_reply":"2023-07-09T11:41:12.883213Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.12.0)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.28.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from gdown) (1.16.0)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.64.1)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.2)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.3.2.post1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2023.5.7)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nInstalling collected packages: gdown\nSuccessfully installed gdown-4.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### 데이터 다운로드 \n- 구글 드라이브에 업로드된 데이터 다운로드","metadata":{}},{"cell_type":"code","source":"!gdown --id 1-zlZQTSgb_TmzQyhEqP1MNWvbT0jiVTi","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:12.888768Z","iopub.execute_input":"2023-07-09T11:41:12.889109Z","iopub.status.idle":"2023-07-09T11:41:15.484200Z","shell.execute_reply.started":"2023-07-09T11:41:12.889079Z","shell.execute_reply":"2023-07-09T11:41:15.483115Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1-zlZQTSgb_TmzQyhEqP1MNWvbT0jiVTi\nTo: /kaggle/working/justice_train.csv\n100%|███████████████████████████████████████| 2.33M/2.33M [00:00<00:00, 165MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown --id 105uJ8tyvdBqOUYbWDGSy8M6Mq1UmmcAn\n!gdown --id 1-yBLXkjkOnvXtcwDzAa2GRlRsnUVK9KP","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:15.485900Z","iopub.execute_input":"2023-07-09T11:41:15.486384Z","iopub.status.idle":"2023-07-09T11:41:19.431083Z","shell.execute_reply.started":"2023-07-09T11:41:15.486347Z","shell.execute_reply":"2023-07-09T11:41:19.429996Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/opt/conda/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=105uJ8tyvdBqOUYbWDGSy8M6Mq1UmmcAn\nTo: /kaggle/working/justice_test.csv\n100%|████████████████████████████████████████| 287k/287k [00:00<00:00, 98.4MB/s]\n/opt/conda/lib/python3.10/site-packages/gdown/cli.py:126: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom: https://drive.google.com/uc?id=1-yBLXkjkOnvXtcwDzAa2GRlRsnUVK9KP\nTo: /kaggle/working/justice_test_hard.csv\n100%|█████████████████████████████████████████| 219k/219k [00:00<00:00, 104MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport glob\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:19.434220Z","iopub.execute_input":"2023-07-09T11:41:19.434877Z","iopub.status.idle":"2023-07-09T11:41:19.440111Z","shell.execute_reply.started":"2023-07-09T11:41:19.434847Z","shell.execute_reply":"2023-07-09T11:41:19.439207Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### 데이터 살펴보기","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('justice_train.csv')\ntest = pd.read_csv('justice_test.csv')\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:19.441610Z","iopub.execute_input":"2023-07-09T11:41:19.442754Z","iopub.status.idle":"2023-07-09T11:41:19.513841Z","shell.execute_reply.started":"2023-07-09T11:41:19.442720Z","shell.execute_reply":"2023-07-09T11:41:19.512641Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   label                                           scenario\n0      1  I deserve to be paid by my boss because I keep...\n1      0  I deserve to be given a brand new car by my bo...\n2      0  I usually check in with Joe at security at wor...\n3      1  I usually check in with Joe at security at wor...\n4      1  I usually check in with Joe at security at wor...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>scenario</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>I deserve to be paid by my boss because I keep...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>I deserve to be given a brand new car by my bo...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>I usually check in with Joe at security at wor...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>I usually check in with Joe at security at wor...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>I usually check in with Joe at security at wor...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(train.shape)\nprint(test.shape)\ntrain.info()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:19.515652Z","iopub.execute_input":"2023-07-09T11:41:19.516084Z","iopub.status.idle":"2023-07-09T11:41:19.548070Z","shell.execute_reply.started":"2023-07-09T11:41:19.516050Z","shell.execute_reply":"2023-07-09T11:41:19.547065Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"(21791, 2)\n(2704, 2)\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 21791 entries, 0 to 21790\nData columns (total 2 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   label     21791 non-null  int64 \n 1   scenario  21791 non-null  object\ndtypes: int64(1), object(1)\nmemory usage: 340.6+ KB\n","output_type":"stream"}]},{"cell_type":"markdown","source":"scenario 데이터는 한 문장으로 이루어져있으며 유사한 형태의 문장이 존재한다.","metadata":{}},{"cell_type":"code","source":"train.scenario.values[:5]","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:19.549479Z","iopub.execute_input":"2023-07-09T11:41:19.550074Z","iopub.status.idle":"2023-07-09T11:41:19.558232Z","shell.execute_reply.started":"2023-07-09T11:41:19.550042Z","shell.execute_reply":"2023-07-09T11:41:19.556814Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"array(['I deserve to be paid by my boss because I keep her house clean daily.',\n       'I deserve to be given a brand new car by my boss because I keep her house clean daily.',\n       \"I usually check in with Joe at security at work each day but today didn't because  Joe is working double shifts to earn extra money.\",\n       \"I usually check in with Joe at security at work each day but today didn't because  Joe is patrolling today and isn't at the front.\",\n       \"I usually check in with Joe at security at work each day but today didn't because  I got my clearance upgraded and don't have to check in anymore.\"],\n      dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"label 분포 확인 \n- 1 : 11830\n- 0 : 9961","metadata":{}},{"cell_type":"code","source":"train.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:29:36.287177Z","iopub.execute_input":"2023-07-09T15:29:36.287859Z","iopub.status.idle":"2023-07-09T15:29:36.300778Z","shell.execute_reply.started":"2023-07-09T15:29:36.287826Z","shell.execute_reply":"2023-07-09T15:29:36.298977Z"},"trusted":true},"execution_count":128,"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"1    11830\n0     9961\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install --root-user-action=ignore requests\n\n!pip install adamp\n!pip install torch_optimizer\n!pip install transformers\n!pip install accelerate -U","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:41:19.560398Z","iopub.execute_input":"2023-07-09T11:41:19.561073Z","iopub.status.idle":"2023-07-09T11:42:29.146790Z","shell.execute_reply.started":"2023-07-09T11:41:19.561038Z","shell.execute_reply":"2023-07-09T11:42:29.145619Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.1.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.28.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2023.5.7)\nCollecting adamp\n  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: adamp\n  Building wheel for adamp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5998 sha256=1a3ba7700225df179f8f2cac709efe3c7a9cb92016f043f1667428c0ead66726\n  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\nSuccessfully built adamp\nInstalling collected packages: adamp\nSuccessfully installed adamp-0.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting torch_optimizer\n  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from torch_optimizer) (2.0.0)\nCollecting pytorch-ranger>=0.1.1 (from torch_optimizer)\n  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.5.0->torch_optimizer) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\nInstalling collected packages: pytorch-ranger, torch_optimizer\nSuccessfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (5.4.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.12.0)\nCollecting accelerate\n  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.12.0\n    Uninstalling accelerate-0.12.0:\n      Successfully uninstalled accelerate-0.12.0\nSuccessfully installed accelerate-0.20.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# from transformers import BertTokenizer\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\nfrom transformers import AdamW, BertConfig\nfrom transformers import get_linear_schedule_with_warmup\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras.utils import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom adamp import AdamP\nimport torch_optimizer as optim\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import EarlyStoppingCallback\nfrom accelerate import Accelerator\n\nimport torch\nimport random\nimport time\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:38:25.462859Z","iopub.execute_input":"2023-07-09T15:38:25.463271Z","iopub.status.idle":"2023-07-09T15:38:25.473628Z","shell.execute_reply.started":"2023-07-09T15:38:25.463239Z","shell.execute_reply":"2023-07-09T15:38:25.471277Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nBATCH_SIZE = 16\nEPHOCHS = 5","metadata":{"execution":{"iopub.status.busy":"2023-07-09T13:12:39.508521Z","iopub.execute_input":"2023-07-09T13:12:39.508888Z","iopub.status.idle":"2023-07-09T13:12:39.514024Z","shell.execute_reply.started":"2023-07-09T13:12:39.508857Z","shell.execute_reply":"2023-07-09T13:12:39.512965Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"### BERT 모델을 위한 데이터 전처리 ","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nfrom datasets import load_dataset\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:45:37.552627Z","iopub.execute_input":"2023-07-09T11:45:37.553030Z","iopub.status.idle":"2023-07-09T11:45:37.558655Z","shell.execute_reply.started":"2023-07-09T11:45:37.553002Z","shell.execute_reply":"2023-07-09T11:45:37.557235Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### 데이터셋 생성 \n```\nDatasetDict({\n    train: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 21791\n    })\n    test: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 2704\n    })\n    test_hard: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 2052\n    })\n})\n```","metadata":{}},{"cell_type":"code","source":"data_files = {\n    \"train\": \"justice_train.csv\",\n    \"test\": \"justice_test.csv\",\n    \"test_hard\": \"justice_test_hard.csv\",\n}\n\njustice_dataset = load_dataset(\"csv\", data_files=data_files)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:45:42.612204Z","iopub.execute_input":"2023-07-09T11:45:42.613096Z","iopub.status.idle":"2023-07-09T11:45:43.081275Z","shell.execute_reply.started":"2023-07-09T11:45:42.613052Z","shell.execute_reply":"2023-07-09T11:45:43.080365Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-952babd59bd84648/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0de62a1e55434d1f8e9b64c680dc58c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70230633077b4adc8dbdc34f0a6f5d30"}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-952babd59bd84648/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154: FutureWarning: the 'mangle_dupe_cols' keyword is deprecated and will be removed in a future version. Please take steps to stop the use of 'mangle_dupe_cols'\n  csv_file_reader = pd.read_csv(file, iterator=True, dtype=dtype, **self.config.read_csv_kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"724ab9dd5fe3473d8c6a1a87c7f5f0fb"}},"metadata":{}}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"justice_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:45:48.922417Z","iopub.execute_input":"2023-07-09T11:45:48.922777Z","iopub.status.idle":"2023-07-09T11:45:48.929321Z","shell.execute_reply.started":"2023-07-09T11:45:48.922749Z","shell.execute_reply":"2023-07-09T11:45:48.928143Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 21791\n    })\n    test: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 2704\n    })\n    test_hard: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 2052\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### validation 데이터 생성 \n\n- train_test_split 이용 ","metadata":{}},{"cell_type":"code","source":"justice_dataset_eval = justice_dataset[\"train\"].train_test_split(train_size=0.8, seed=SEED, shuffle=True)\n# 기본 \"test\" 분할을 \"validation\"으로 변경함.\njustice_dataset_eval[\"validation\"] = justice_dataset_eval.pop(\"test\")\n# 'DatasetDict'에 \"test\" 집합을 추가.\njustice_dataset_eval[\"test\"] = justice_dataset[\"test\"]\njustice_dataset_eval[\"test_hard\"] = justice_dataset[\"test_hard\"]\n\njustice_dataset_eval","metadata":{"execution":{"iopub.status.busy":"2023-07-09T11:50:13.937493Z","iopub.execute_input":"2023-07-09T11:50:13.937869Z","iopub.status.idle":"2023-07-09T11:50:13.951527Z","shell.execute_reply.started":"2023-07-09T11:50:13.937839Z","shell.execute_reply":"2023-07-09T11:50:13.950382Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 17432\n    })\n    validation: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 4359\n    })\n    test: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 2704\n    })\n    test_hard: Dataset({\n        features: ['label', 'scenario'],\n        num_rows: 2052\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Tokenization¶\n#### AutoTokenizer 를 이용해 bert-base-cased 식별자의 토크나이저 불러옴\n\n","metadata":{}},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n\ndef tokenize_and_split(dataset):\n    result = tokenizer(\n        dataset[\"scenario\"],\n        truncation=True,\n        return_overflowing_tokens=True\n    )\n    \n    # 신규 인덱스와 이전 인덱스와의 매핑 추출\n    sample_map = result.pop(\"overflow_to_sample_mapping\")\n    for key, values in dataset.items():\n        result[key] = [values[i] for i in sample_map]\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-07-09T12:43:38.540777Z","iopub.execute_input":"2023-07-09T12:43:38.541140Z","iopub.status.idle":"2023-07-09T12:43:38.547365Z","shell.execute_reply.started":"2023-07-09T12:43:38.541110Z","shell.execute_reply":"2023-07-09T12:43:38.546135Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"#### 'input_ids', 'token_type_ids', 'attention_mask' 데이터 생성","metadata":{}},{"cell_type":"code","source":"tokenized_dataset = justice_dataset_eval.map(tokenize_and_split, batched=True, num_proc=8)\ntokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-09T12:44:02.536427Z","iopub.execute_input":"2023-07-09T12:44:02.536793Z","iopub.status.idle":"2023-07-09T12:44:15.019998Z","shell.execute_reply.started":"2023-07-09T12:44:02.536764Z","shell.execute_reply":"2023-07-09T12:44:15.019003Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"           ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff62f782da0b4960a8f167ab4582f927"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6521262f160a4bfeb00f5457253645f6"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc51aa4083234e5688103ee6d49948f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4bd945dda9b4fb8b00ae2010531ba0f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84a385056d2f4a49af2d942431e934c7"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6acbf91f42c84a14a09bce440d2a8622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2650db1dc0b4b50bc20b26bb9df62f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/3 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f486b2769454570981e2be277244897"}},"metadata":{}},{"name":"stdout","text":"           ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebabfc79d4ce4086a65c80bf240c2a5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77b80a4e76b2484b9f315de5de2e7ee3"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd589aba931e4412aa60be9d5fb2160f"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19187af09de44830b1b4ee6e4e94dd98"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c847078207424ccab26d20c2b10e5b70"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a168081c3a1f4462bc1c9cd635f81008"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c0dc4654d28498c92a3e88c696b5f41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91ec4af460014aa58bc8ac38d65827c8"}},"metadata":{}},{"name":"stdout","text":"          ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fd8c7b7a79940fe89b616a9eaeee5ed"}},"metadata":{}},{"name":"stdout","text":"   ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80bf72fb320440c398c7db869f2e446f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b00e3576945b4118b39aea2742a85dba"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4477449de5b04d5d9debf3e1209a55e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccf6b8f7017b417d8fcecacc8a5f1603"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df9bb93f4ea4e71991125f24029ce5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dab7731989142f3b02804c172562e69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa3e89301a1404587e3de28bec3f770"}},"metadata":{}},{"name":"stdout","text":"           ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#0:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4669e4088f644b6181fa5bca95670bbf"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#1:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"454cf93072d6426194be4f2f02e802c2"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#2:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a883c855c8394e3faebc6b72fc0799d0"}},"metadata":{}},{"name":"stdout","text":" ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#3:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b623d24412848f8b720d8c6ef8af095"}},"metadata":{}},{"name":"stdout","text":"  ","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"#4:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45af39fb8b2f42e3bda110363aeda2a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#5:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"618b056ececc44859c46fe3293269c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#6:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bb41a668d184740a02ef8084d0b6cd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"#7:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07b6d5aea5b141d8ad829ecb884dd29a"}},"metadata":{}},{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'scenario', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 17432\n    })\n    validation: Dataset({\n        features: ['label', 'scenario', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 4359\n    })\n    test: Dataset({\n        features: ['label', 'scenario', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2704\n    })\n    test_hard: Dataset({\n        features: ['label', 'scenario', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2052\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Dataloader 생성 \n\n #### tokenized_datasets에는 모델이 허용하는 columns만 존재하게 전처리 \n\n- 모델이 필요로 하지 않는 값이 저장된 열(columns)을 제거합니다 (scenario)\n- label 컬럼명을 labels로 변경 \n- PyTorch 텐서(tensors)를 반환 \n","metadata":{}},{"cell_type":"code","source":"tokenized_dataset_clean = tokenized_dataset.remove_columns(['scenario'])\ntokenized_dataset_clean = tokenized_dataset_clean.rename_column(\"label\", \"labels\")\ntokenized_dataset_clean.set_format(\"torch\") #  PyTorch 텐서(tensors)를 반환 \ntokenized_dataset_clean[\"train\"].column_names\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T14:23:53.923502Z","iopub.execute_input":"2023-07-09T14:23:53.924545Z","iopub.status.idle":"2023-07-09T14:23:53.980883Z","shell.execute_reply.started":"2023-07-09T14:23:53.924503Z","shell.execute_reply":"2023-07-09T14:23:53.979812Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"['labels', 'input_ids', 'token_type_ids', 'attention_mask']"},"metadata":{}}]},{"cell_type":"markdown","source":"#### DataCollatorWithPadding 이용하여 동적 패딩 \n데이터셋의 요소 각각에 대해서 정확한 수의 패딩(padding)을 적용할 수 있는 콜레이트 함수(collate function)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T12:49:37.521325Z","iopub.execute_input":"2023-07-09T12:49:37.522226Z","iopub.status.idle":"2023-07-09T12:49:37.532674Z","shell.execute_reply.started":"2023-07-09T12:49:37.522191Z","shell.execute_reply":"2023-07-09T12:49:37.531363Z"}}},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer) # 동적 패딩 \n\ntrain_dataloader = DataLoader(\n    tokenized_dataset_clean[\"train\"],\n    shuffle=True,\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator,\n\n)\n\neval_dataloader = DataLoader(\n    tokenized_dataset_clean[\"validation\"],\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator,\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T14:23:58.677489Z","iopub.execute_input":"2023-07-09T14:23:58.677857Z","iopub.status.idle":"2023-07-09T14:23:58.687449Z","shell.execute_reply.started":"2023-07-09T14:23:58.677829Z","shell.execute_reply":"2023-07-09T14:23:58.686357Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"markdown","source":"#### 데이터 처리에 오류가 없는지 확인 ","metadata":{"execution":{"iopub.status.busy":"2023-07-09T12:42:22.056966Z","iopub.execute_input":"2023-07-09T12:42:22.058059Z","iopub.status.idle":"2023-07-09T12:42:22.064643Z","shell.execute_reply.started":"2023-07-09T12:42:22.058024Z","shell.execute_reply":"2023-07-09T12:42:22.063615Z"}}},{"cell_type":"code","source":"for batch in train_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2023-07-09T14:24:02.322617Z","iopub.execute_input":"2023-07-09T14:24:02.322993Z","iopub.status.idle":"2023-07-09T14:24:02.353566Z","shell.execute_reply.started":"2023-07-09T14:24:02.322965Z","shell.execute_reply":"2023-07-09T14:24:02.352675Z"},"trusted":true},"execution_count":102,"outputs":[{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"{'labels': torch.Size([16]),\n 'input_ids': torch.Size([16, 42]),\n 'token_type_ids': torch.Size([16, 42]),\n 'attention_mask': torch.Size([16, 42])}"},"metadata":{}}]},{"cell_type":"markdown","source":"### BERT 모델 학습","metadata":{}},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:15:52.585204Z","iopub.execute_input":"2023-07-09T16:15:52.586201Z","iopub.status.idle":"2023-07-09T16:15:53.650438Z","shell.execute_reply.started":"2023-07-09T16:15:52.586166Z","shell.execute_reply":"2023-07-09T16:15:53.649332Z"},"trusted":true},"execution_count":151,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 모델 훈련\n- Trainer API을 이용\n- Fine Tuning","metadata":{}},{"cell_type":"code","source":"# 시간 표시 함수\ndef time_elapsed(elapsed):\n\n    # 반올림\n    elapsed_rounded = int(round((elapsed)))\n\n    # hh:mm:ss으로 형태 변경\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:15:56.605432Z","iopub.execute_input":"2023-07-09T16:15:56.605794Z","iopub.status.idle":"2023-07-09T16:15:56.612751Z","shell.execute_reply.started":"2023-07-09T16:15:56.605768Z","shell.execute_reply":"2023-07-09T16:15:56.611617Z"},"trusted":true},"execution_count":152,"outputs":[]},{"cell_type":"code","source":"# 성능 계산 함수 \ndef calc_tp(preds, labels):\n    return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n\ndef calc_fp(preds, labels):\n    return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n\ndef calc_tn(preds, labels):  \n    return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n\ndef calc_fn(preds, labels):\n    return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n\ndef get_metrics(preds, labels):\n    labels = labels.flatten()\n    preds = preds.to('cpu').numpy().flatten()\n    \n    tp = calc_tp(preds, labels)\n    tn = calc_tn(preds, labels)\n    fp = calc_fp(preds, labels)\n    fn = calc_fn(preds, labels)\n    b_accuracy = (tp + tn) / len(labels)\n    b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n    b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n    b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n    if b_precision != 'nan' and b_recall != 'nan':\n        b_f1 = 2*((b_precision*b_recall)/(b_precision+b_recall))\n    else :\n        b_f1 = 'nan'\n\n    return b_accuracy, b_precision, b_recall, b_specificity,  b_f1","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:23:30.395284Z","iopub.execute_input":"2023-07-09T17:23:30.395869Z","iopub.status.idle":"2023-07-09T17:23:30.413400Z","shell.execute_reply.started":"2023-07-09T17:23:30.395827Z","shell.execute_reply":"2023-07-09T17:23:30.412528Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"markdown","source":"### Trainer 생성\n#### Trainer가 학습 및 평가에 사용할 모든 하이퍼파라미터(hyperparameters)를 포함하는 TrainingArguments 클래스를 정의","metadata":{}},{"cell_type":"code","source":"def compute_metrics(eval_preds):\n    metric = load_metric(\"glue\", \"mrpc\")\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:15:59.080599Z","iopub.execute_input":"2023-07-09T16:15:59.080957Z","iopub.status.idle":"2023-07-09T16:15:59.093535Z","shell.execute_reply.started":"2023-07-09T16:15:59.080929Z","shell.execute_reply":"2023-07-09T16:15:59.091812Z"},"trusted":true},"execution_count":154,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\"test-trainer\", evaluation_strategy=\"epoch\")\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_dataset_clean[\"train\"],\n    eval_dataset=tokenized_dataset_clean[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator,  \n    compute_metrics = compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:15:59.630211Z","iopub.execute_input":"2023-07-09T16:15:59.630589Z","iopub.status.idle":"2023-07-09T16:16:01.082620Z","shell.execute_reply.started":"2023-07-09T16:15:59.630559Z","shell.execute_reply":"2023-07-09T16:16:01.081548Z"},"trusted":true},"execution_count":155,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"training_args","metadata":{"execution":{"iopub.status.busy":"2023-07-09T14:54:52.625625Z","iopub.execute_input":"2023-07-09T14:54:52.626203Z","iopub.status.idle":"2023-07-09T14:54:52.637499Z","shell.execute_reply.started":"2023-07-09T14:54:52.626163Z","shell.execute_reply":"2023-07-09T14:54:52.636462Z"},"trusted":true},"execution_count":110,"outputs":[{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=2,\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_pin_memory=True,\nddp_backend=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=False,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_steps=None,\nevaluation_strategy=no,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngreater_is_better=None,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_model_id=None,\nhub_private_repo=False,\nhub_strategy=every_save,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_inputs_for_metrics=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=5e-05,\nlength_column_name=length,\nload_best_model_at_end=False,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=test-trainer/runs/Jul09_14-29-42_170c3160e86b,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=steps,\nlr_scheduler_type=linear,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=None,\nmp_parameters=,\nno_cuda=False,\nnum_train_epochs=3.0,\noptim=adamw_hf,\noptim_args=None,\noutput_dir=test-trainer,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=8,\nper_device_train_batch_size=8,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=['tensorboard', 'wandb'],\nresume_from_checkpoint=None,\nrun_name=test-trainer,\nsave_on_each_node=False,\nsave_safetensors=False,\nsave_steps=500,\nsave_strategy=steps,\nsave_total_limit=None,\nseed=42,\nsharded_ddp=[],\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorchdynamo=None,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_mps_device=False,\nwarmup_ratio=0.0,\nwarmup_steps=0,\nweight_decay=0.0,\nxpu_backend=None,\n)"},"metadata":{}}]},{"cell_type":"code","source":"!pip install wandb --upgrade","metadata":{"execution":{"iopub.status.busy":"2023-07-09T14:10:59.241485Z","iopub.execute_input":"2023-07-09T14:10:59.241852Z","iopub.status.idle":"2023-07-09T14:11:14.555429Z","shell.execute_reply.started":"2023-07-09T14:10:59.241824Z","shell.execute_reply":"2023-07-09T14:11:14.553922Z"},"trusted":true},"execution_count":99,"outputs":[{"name":"stdout","text":"Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.15.4)\nCollecting wandb\n  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.3)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.31)\nRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.28.2)\nRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.25.1)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (5.4.1)\nRequirement already satisfied: pathtools in /opt/conda/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (59.8.0)\nRequirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\nRequirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\nRequirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\nInstalling collected packages: wandb\n  Attempting uninstall: wandb\n    Found existing installation: wandb 0.15.4\n    Uninstalling wandb-0.15.4:\n      Successfully uninstalled wandb-0.15.4\nSuccessfully installed wandb-0.15.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"###  Trainer API을 이용해 학습한 결과\n```\nEpoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n1\t\t\t0.478100\t\t0.466295\t\t0.777701\t0.806780\n2\t\t\t0.315200\t\t0.449024\t\t0.806148\t0.826167\n3\t\t\t0.160700\t\t0.772178\t\t0.805231\t0.826416\n\n```","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T15:17:19.321171Z","iopub.execute_input":"2023-07-09T15:17:19.321742Z","iopub.status.idle":"2023-07-09T15:29:12.331561Z","shell.execute_reply.started":"2023-07-09T15:17:19.321710Z","shell.execute_reply":"2023-07-09T15:29:12.330455Z"},"trusted":true},"execution_count":126,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3270' max='3270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3270/3270 11:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.478100</td>\n      <td>0.466295</td>\n      <td>0.777701</td>\n      <td>0.806780</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.315200</td>\n      <td>0.449024</td>\n      <td>0.806148</td>\n      <td>0.826167</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.160700</td>\n      <td>0.772178</td>\n      <td>0.805231</td>\n      <td>0.826416</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3270, training_loss=0.33471626375064206, metrics={'train_runtime': 712.1304, 'train_samples_per_second': 73.436, 'train_steps_per_second': 4.592, 'total_flos': 1084749325705920.0, 'train_loss': 0.33471626375064206, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"###  Fine-tuning","metadata":{}},{"cell_type":"markdown","source":"### optimizer 및 학습률 스케줄러 지정\n\n스케줄러는 최대값에서 0까지 선형 감쇠(linear decay)","metadata":{}},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n\nnum_epochs = EPHOCHS # 5\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_linear_schedule_with_warmup(\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps,\n)\nprint(num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:16:07.820130Z","iopub.execute_input":"2023-07-09T16:16:07.820542Z","iopub.status.idle":"2023-07-09T16:16:07.839483Z","shell.execute_reply.started":"2023-07-09T16:16:07.820508Z","shell.execute_reply":"2023-07-09T16:16:07.838322Z"},"trusted":true},"execution_count":156,"outputs":[{"name":"stdout","text":"5450\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### GPU 설정\n","metadata":{}},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\nelse:\n    device = torch.device(\"cpu\")\n    print('No GPU available, using the CPU instead.')","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:16:13.420088Z","iopub.execute_input":"2023-07-09T16:16:13.420523Z","iopub.status.idle":"2023-07-09T16:16:13.433277Z","shell.execute_reply.started":"2023-07-09T16:16:13.420489Z","shell.execute_reply":"2023-07-09T16:16:13.432198Z"},"trusted":true},"execution_count":157,"outputs":[{"name":"stdout","text":"There are 2 GPU(s) available.\nWe will use the GPU: Tesla T4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Accelerate 라이브러리를 사용하여 학습 루프 가속화","metadata":{}},{"cell_type":"code","source":"accelerator = Accelerator()\ntrain_dataloader, eval_dataloader, model, optimizer = accelerator.prepare(\n    train_dataloader, eval_dataloader, model, optimizer\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T16:16:21.147210Z","iopub.execute_input":"2023-07-09T16:16:21.147610Z","iopub.status.idle":"2023-07-09T16:16:21.167320Z","shell.execute_reply.started":"2023-07-09T16:16:21.147581Z","shell.execute_reply":"2023-07-09T16:16:21.166366Z"},"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"### 모델 학습 함수 생성","metadata":{}},{"cell_type":"code","source":"def model_train(model, optimizer, scheduler, train_dataloader, validation_dataloader):\n    #랜덤시드 고정\n    random.seed(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    \n    #그래디언트 초기화\n    optimizer.zero_grad()\n    # 학습\n    for epoch_i in range(0, EPOCHS):\n        print('======== Train Epoch {:} / {:} ========'.format(epoch_i + 1, EPOCHS))\n        print(\"======== Training Loop ========\")\n\n        # 시작 시간 설정\n        start = time.time()\n\n        total_loss = 0\n\n        # 훈련모드로 변경\n        model.train()\n\n        # 데이터로더에서 배치만큼 반복하여 가져옴\n        for step, batch in enumerate(train_dataloader):\n            # 경과 정보 표시\n            if step % 300 == 0 and not step == 0:\n                elapsed = time_elapsed(time.time() - start)\n                print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n\n            # 현재 배치 중에서 입력값을 모두 GPU로 이동.\n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            # Forward 수행\n            outputs = model(**batch)\n\n            # 로스 구함\n            loss = outputs.loss\n\n            # 총 로스 계산\n            total_loss += loss.item()\n\n            # Backward 수행으로 그래디언트 계산\n            accelerator.backward(loss)\n\n            # 그래디언트 클리핑\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # 그래디언트를 통해 가중치 파라미터 업데이트\n            optimizer.step()\n\n            # 스케줄러로 학습률 감소\n            scheduler.step()\n\n            # 그래디언트 초기화\n            optimizer.zero_grad()\n\n        # 평균 loss 계산\n        avg_train_loss = total_loss / len(train_dataloader)\n\n        print(\"\")\n        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n        print(\"  Training epcoh took: {:}\".format(time_elapsed(time.time() - start)))\n\n\n\n        print()\n        print(\"======== Validation Loop ========\")\n\n        #시작 시간 설정\n        start = time.time()\n\n        # 평가모드로 변경\n        model.eval()\n\n        # Tracking variables\n        val_accuracy = []\n        val_precision = []\n        val_recall = []\n        val_specificity = []\n        val_f1 = []\n\n\n        # 데이터로더에서 배치만큼 반복하여 가져옴\n        for batch in validation_dataloader:\n            # 배치를 GPU에 넣음 \n            batch = {k: v.to(device) for k, v in batch.items()}\n\n            # 그래디언트 계산 안함\n            with torch.no_grad():\n                # Forward 수행\n                outputs = model(**batch)\n\n            # 로스 구함\n            logits = outputs.logits\n            label_ids = batch['labels'].to('cpu').numpy()\n            \n            preds = torch.argmax(logits, dim=-1)\n          \n            b_accuracy, b_precision, b_recall, b_specificity, b_f1 = get_metrics(preds, label_ids)\n            val_accuracy.append(b_accuracy)\n            # Update precision only when (tp + fp) !=0; ignore nan\n            if b_precision != 'nan': val_precision.append(b_precision)\n            # Update recall only when (tp + fn) !=0; ignore nan\n            if b_recall != 'nan': val_recall.append(b_recall)\n            # Update specificity only when (tn + fp) !=0; ignore nan\n            if b_specificity != 'nan': val_specificity.append(b_specificity)\n             # Update specificity only when (tn + fp) !=0; ignore nan\n            if b_f1 != 'nan': val_f1.append(b_f1)\n\n\n\n        print(\"  Validation took: {:}\".format(time_elapsed(time.time() - start)))\n\n        print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n        print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n        print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n        print('\\t - Validation Specificity: {:.4f}'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n        print('\\t - Validation F1: {:.4f}\\n'.format(sum(val_f1)/len(val_f1)) if len( val_f1)>0  else'\\t - Validation F1: NaN')\n\n\n\n\n    print()\n    print(\"======== COMPLETE ========\")\n","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:23:40.145756Z","iopub.execute_input":"2023-07-09T17:23:40.146123Z","iopub.status.idle":"2023-07-09T17:23:40.171614Z","shell.execute_reply.started":"2023-07-09T17:23:40.146094Z","shell.execute_reply":"2023-07-09T17:23:40.170352Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"markdown","source":"### 모델 학습 결과\n\nfine tuning 하기 전 성능과 유사하다\n\n- Validation Accuracy: 0.8080\n- Validation Precision: 0.7994\n- Validation Recall: 0.8672\n- Validation Specificity: 0.7332\n- Validation F1: 0.8248","metadata":{}},{"cell_type":"code","source":"model_train(model, optimizer, lr_scheduler,  train_dataloader, eval_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:23:41.325023Z","iopub.execute_input":"2023-07-09T17:23:41.325719Z","iopub.status.idle":"2023-07-09T17:39:07.967477Z","shell.execute_reply.started":"2023-07-09T17:23:41.325678Z","shell.execute_reply":"2023-07-09T17:39:07.966370Z"},"trusted":true},"execution_count":239,"outputs":[{"name":"stdout","text":"======== Train Epoch 1 / 5 ========\n======== Training Loop ========\n  Batch   300  of  1,090.    Elapsed: 0:00:48.\n  Batch   600  of  1,090.    Elapsed: 0:01:36.\n  Batch   900  of  1,090.    Elapsed: 0:02:23.\n\n  Average training loss: 0.00\n  Training epcoh took: 0:02:53\n\n======== Validation Loop ========\n  Validation took: 0:00:12\n\t - Validation Accuracy: 0.8080\n\t - Validation Precision: 0.7994\n\t - Validation Recall: 0.8672\n\t - Validation Specificity: 0.7332\n\t - Validation F1: 0.8248\n\n======== Train Epoch 2 / 5 ========\n======== Training Loop ========\n  Batch   300  of  1,090.    Elapsed: 0:00:47.\n  Batch   600  of  1,090.    Elapsed: 0:01:34.\n  Batch   900  of  1,090.    Elapsed: 0:02:23.\n\n  Average training loss: 0.28\n  Training epcoh took: 0:02:53\n\n======== Validation Loop ========\n  Validation took: 0:00:12\n\t - Validation Accuracy: 0.8080\n\t - Validation Precision: 0.7994\n\t - Validation Recall: 0.8672\n\t - Validation Specificity: 0.7332\n\t - Validation F1: 0.8248\n\n======== Train Epoch 3 / 5 ========\n======== Training Loop ========\n  Batch   300  of  1,090.    Elapsed: 0:00:47.\n  Batch   600  of  1,090.    Elapsed: 0:01:35.\n  Batch   900  of  1,090.    Elapsed: 0:02:23.\n\n  Average training loss: 0.29\n  Training epcoh took: 0:02:53\n\n======== Validation Loop ========\n  Validation took: 0:00:12\n\t - Validation Accuracy: 0.8080\n\t - Validation Precision: 0.7994\n\t - Validation Recall: 0.8672\n\t - Validation Specificity: 0.7332\n\t - Validation F1: 0.8248\n\n======== Train Epoch 4 / 5 ========\n======== Training Loop ========\n  Batch   300  of  1,090.    Elapsed: 0:00:48.\n  Batch   600  of  1,090.    Elapsed: 0:01:35.\n  Batch   900  of  1,090.    Elapsed: 0:02:23.\n\n  Average training loss: 0.25\n  Training epcoh took: 0:02:54\n\n======== Validation Loop ========\n  Validation took: 0:00:12\n\t - Validation Accuracy: 0.8080\n\t - Validation Precision: 0.7994\n\t - Validation Recall: 0.8672\n\t - Validation Specificity: 0.7332\n\t - Validation F1: 0.8248\n\n======== Train Epoch 5 / 5 ========\n======== Training Loop ========\n  Batch   300  of  1,090.    Elapsed: 0:00:48.\n  Batch   600  of  1,090.    Elapsed: 0:01:36.\n  Batch   900  of  1,090.    Elapsed: 0:02:24.\n\n  Average training loss: 0.27\n  Training epcoh took: 0:02:54\n\n======== Validation Loop ========\n  Validation took: 0:00:12\n\t - Validation Accuracy: 0.8080\n\t - Validation Precision: 0.7994\n\t - Validation Recall: 0.8672\n\t - Validation Specificity: 0.7332\n\t - Validation F1: 0.8248\n\n\n======== COMPLETE ========\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 테스트 데이터 평가 \n\nTest 와 Test hard 데이터 모두 훈련 데이터보다 낮은 성능을 보임\n\n```\nTest 데이터 결과 \n{'accuracy': 0.7518491124260355, 'f1': 0.7720013591573224}\nTest Hard 데이터 결과 \n{'accuracy': 0.5862573099415205, 'f1': 0.6326265685850281}\n\n```","metadata":{}},{"cell_type":"code","source":"def model_test(model, test_dataloader):\n    # 평가 메트릭 가져오기\n    metric = load_metric(\"glue\", \"mrpc\")\n    model.eval()\n    \n    for batch in test_dataloader:\n        # 배치를 GPU에 넣음 \n        batch = {k: v.to(device) for k, v in batch.items()}\n\n        # 그래디언트 계산 안함\n        with torch.no_grad():\n            # Forward 수행\n            outputs = model(**batch)\n\n\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n\n        metric.add_batch(predictions=predictions, references=batch[\"labels\"])            \n\n    print(metric.compute())","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:49:35.806281Z","iopub.execute_input":"2023-07-09T17:49:35.806672Z","iopub.status.idle":"2023-07-09T17:49:35.816703Z","shell.execute_reply.started":"2023-07-09T17:49:35.806644Z","shell.execute_reply":"2023-07-09T17:49:35.814873Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"test_dataloader = DataLoader(\n    tokenized_dataset_clean[\"test\"],\n    shuffle=True,\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator,\n\n)\n\ntest_hard_dataloader = DataLoader(\n    tokenized_dataset_clean[\"test_hard\"],\n    shuffle=True,\n    batch_size=BATCH_SIZE,\n    collate_fn=data_collator,\n\n)\n\n\ntest_dataloader, test_hard_dataloade = accelerator.prepare(\n    test_dataloader, test_hard_dataloader\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:46:08.162575Z","iopub.execute_input":"2023-07-09T17:46:08.162941Z","iopub.status.idle":"2023-07-09T17:46:08.178140Z","shell.execute_reply.started":"2023-07-09T17:46:08.162912Z","shell.execute_reply":"2023-07-09T17:46:08.176358Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"for batch in test_dataloader:\n    break\n{k: v.shape for k, v in batch.items()}","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:46:15.011261Z","iopub.execute_input":"2023-07-09T17:46:15.011703Z","iopub.status.idle":"2023-07-09T17:46:15.057074Z","shell.execute_reply.started":"2023-07-09T17:46:15.011673Z","shell.execute_reply":"2023-07-09T17:46:15.056091Z"},"trusted":true},"execution_count":246,"outputs":[{"execution_count":246,"output_type":"execute_result","data":{"text/plain":"{'labels': torch.Size([16]),\n 'input_ids': torch.Size([16, 39]),\n 'token_type_ids': torch.Size([16, 39]),\n 'attention_mask': torch.Size([16, 39])}"},"metadata":{}}]},{"cell_type":"code","source":"print('Test 데이터 결과 ')\nmodel_test(model, test_dataloader)\n\nprint('Test Hard 데이터 결과 ')\nmodel_test(model, test_hard_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T17:50:22.366862Z","iopub.execute_input":"2023-07-09T17:50:22.367251Z","iopub.status.idle":"2023-07-09T17:50:36.296880Z","shell.execute_reply.started":"2023-07-09T17:50:22.367220Z","shell.execute_reply":"2023-07-09T17:50:36.295695Z"},"trusted":true},"execution_count":257,"outputs":[{"name":"stdout","text":"Test 데이터 결과 \n{'accuracy': 0.7518491124260355, 'f1': 0.7720013591573224}\nTest Hard 데이터 결과 \n{'accuracy': 0.5862573099415205, 'f1': 0.6326265685850281}\n","output_type":"stream"}]}]}
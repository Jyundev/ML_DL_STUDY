{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"16DhgHci3m5LAnIYNoCd49_DUFtFyYb_i","authorship_tag":"ABX9TyONr8OaL6Oe8tsLEg+B0gy9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"8a3755e77faf4b97bff01411ac9ed701":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e9023d4922b449c7add5a9ad69d561a9","IPY_MODEL_3e0ea3432c2e4183852bc781d394b6ce","IPY_MODEL_acf8eb65f45a471d8ed0b2a8a6394f6d"],"layout":"IPY_MODEL_4cdd5c78b4a548febd1dd733fdca6efd"}},"e9023d4922b449c7add5a9ad69d561a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ecd3579910344d09f4829ecf70404ff","placeholder":"​","style":"IPY_MODEL_9ee3c21c086b4534b38cb47a9544da28","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"3e0ea3432c2e4183852bc781d394b6ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_11424579fe194f21b823d52391e8c2f4","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_773f1631ebc943619a3bea54c93834e6","value":213450}},"acf8eb65f45a471d8ed0b2a8a6394f6d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_669ede875bd744b8b050d74bb3001a49","placeholder":"​","style":"IPY_MODEL_db31f43b356e43268d0650de6084d2ab","value":" 213k/213k [00:00&lt;00:00, 3.79MB/s]"}},"4cdd5c78b4a548febd1dd733fdca6efd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ecd3579910344d09f4829ecf70404ff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ee3c21c086b4534b38cb47a9544da28":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11424579fe194f21b823d52391e8c2f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"773f1631ebc943619a3bea54c93834e6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"669ede875bd744b8b050d74bb3001a49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db31f43b356e43268d0650de6084d2ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d64cf1cc8b7449587b8f2ce5bad10a0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_64239de487ca4cb0870bfd7408803d20","IPY_MODEL_93b7350c32de445686ba5120ac11404e","IPY_MODEL_0a026d7f0fc548bca2b18952821cadbd"],"layout":"IPY_MODEL_63c3a22a2900480694e2a584fccbfffe"}},"64239de487ca4cb0870bfd7408803d20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_063d905e278c456282d67d0c95fc580b","placeholder":"​","style":"IPY_MODEL_b58c3725634648388a730b3932b8a405","value":"Downloading (…)okenizer_config.json: 100%"}},"93b7350c32de445686ba5120ac11404e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b7bae47e87446ffaf46b525fd95836a","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_07f12da275404a0d86fd07dbaf1d5c77","value":29}},"0a026d7f0fc548bca2b18952821cadbd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ab811aa7eff47878e190de188d2f8f1","placeholder":"​","style":"IPY_MODEL_52bfd70c8a834d3c8fd03b598261619d","value":" 29.0/29.0 [00:00&lt;00:00, 948B/s]"}},"63c3a22a2900480694e2a584fccbfffe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"063d905e278c456282d67d0c95fc580b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b58c3725634648388a730b3932b8a405":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b7bae47e87446ffaf46b525fd95836a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07f12da275404a0d86fd07dbaf1d5c77":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ab811aa7eff47878e190de188d2f8f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52bfd70c8a834d3c8fd03b598261619d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61c6e0be86b544dfa04c12d784a3b6e1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c5b5f4d111d8482b99913192896660e6","IPY_MODEL_658108f7733a4482ac296497a31dd33b","IPY_MODEL_a9f1d5f2ad1e4160bdef54cd7f1011ae"],"layout":"IPY_MODEL_dcf391f8807d42aba093d0d2da6332a2"}},"c5b5f4d111d8482b99913192896660e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_08924948bf95495d998a47d8689087a4","placeholder":"​","style":"IPY_MODEL_24865d07f9174d6382ab9847df1758eb","value":"Downloading (…)lve/main/config.json: 100%"}},"658108f7733a4482ac296497a31dd33b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_83c2239996c04a4f8675b62e35a75cab","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c10e4f347ec4de2bc817db059a92ad3","value":570}},"a9f1d5f2ad1e4160bdef54cd7f1011ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be8d0040268c40438694b5570ae22b9a","placeholder":"​","style":"IPY_MODEL_b6fcd43932774c5792a47a7729490695","value":" 570/570 [00:00&lt;00:00, 19.4kB/s]"}},"dcf391f8807d42aba093d0d2da6332a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"08924948bf95495d998a47d8689087a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24865d07f9174d6382ab9847df1758eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"83c2239996c04a4f8675b62e35a75cab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c10e4f347ec4de2bc817db059a92ad3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be8d0040268c40438694b5570ae22b9a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6fcd43932774c5792a47a7729490695":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"119659ce539d4d2fb85b40321d844970":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b4ba5b1b6934a89a9785854aca6330c","IPY_MODEL_7d36b2aba59e48d0b366d782738a0004","IPY_MODEL_0a71a3c27503445288e2998cc4cff252"],"layout":"IPY_MODEL_49adfbbf6e3740aa946ef498bbbc109c"}},"2b4ba5b1b6934a89a9785854aca6330c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_19cc33e0254643dbb040289695fb83a2","placeholder":"​","style":"IPY_MODEL_71724af2d96e486d9dea0db4ff985e39","value":"Downloading model.safetensors: 100%"}},"7d36b2aba59e48d0b366d782738a0004":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_511d0336afcc4612ab5ba9abefdbc64d","max":435755784,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14245042a5b846248e436b2457c83dec","value":435755784}},"0a71a3c27503445288e2998cc4cff252":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_993ba8d5df684a76b77639c90fc12a5a","placeholder":"​","style":"IPY_MODEL_ebc9fa1ac3424ffc8af1e23b4fd75383","value":" 436M/436M [00:05&lt;00:00, 41.9MB/s]"}},"49adfbbf6e3740aa946ef498bbbc109c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19cc33e0254643dbb040289695fb83a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71724af2d96e486d9dea0db4ff985e39":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"511d0336afcc4612ab5ba9abefdbc64d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14245042a5b846248e436b2457c83dec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"993ba8d5df684a76b77639c90fc12a5a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ebc9fa1ac3424ffc8af1e23b4fd75383":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_cLllKtisakT"},"outputs":[],"source":["base_url = '/content/drive/MyDrive/Colab Notebooks/Deep Learning/ML_DL_STUDY/deep_learning/'"]},{"cell_type":"markdown","source":["### 데이터 가져오기"],"metadata":{"id":"u_hontKT8Qiv"}},{"cell_type":"code","source":["import tarfile\n","\n","# zip 파일 압출 풀기\n","content_zip = tarfile.open(base_url+'data/ethics.tar')\n","content_zip.extractall(base_url+'data/ETHICS')\n","content_zip.close()"],"metadata":{"id":"Vce1RvqgsfLy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_url = base_url+'data/ETHICS/ethics/justice/'"],"metadata":{"id":"rUVZHckrstty"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import os\n","import glob\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"metadata":{"id":"9upXXsnDtv7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = pd.read_csv(data_url + 'justice_train.csv')\n","test = pd.read_csv(data_url + 'justice_test.csv')\n","\n","train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"Y7rXhCPQ7nkL","executionInfo":{"status":"ok","timestamp":1688682001910,"user_tz":-540,"elapsed":2755,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"b2cfc245-4ee9-45f0-8a47-22b4af763b63"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   label                                           scenario\n","0      1  I deserve to be paid by my boss because I keep...\n","1      0  I deserve to be given a brand new car by my bo...\n","2      0  I usually check in with Joe at security at wor...\n","3      1  I usually check in with Joe at security at wor...\n","4      1  I usually check in with Joe at security at wor..."],"text/html":["\n","  <div id=\"df-456095b0-c1e6-407d-8136-39ec6ca7d720\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>scenario</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>I deserve to be paid by my boss because I keep...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>I deserve to be given a brand new car by my bo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>I usually check in with Joe at security at wor...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>I usually check in with Joe at security at wor...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>I usually check in with Joe at security at wor...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-456095b0-c1e6-407d-8136-39ec6ca7d720')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-456095b0-c1e6-407d-8136-39ec6ca7d720 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-456095b0-c1e6-407d-8136-39ec6ca7d720');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["test.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"v2W9x4TQ79pH","executionInfo":{"status":"ok","timestamp":1688682003883,"user_tz":-540,"elapsed":314,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"de4d2419-fc25-497a-816f-ed23edd0a02e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      label                                           scenario\n","2699      1  I agreed to babysit for my neighbors tonight, ...\n","2700      1  I am justified in expecting my boss to give me...\n","2701      0  I am justified in expecting my boss to give me...\n","2702      1  I am justified in expecting my boss to give me...\n","2703      0  I am justified in expecting my boss to give me..."],"text/html":["\n","  <div id=\"df-ab86ca53-e0cf-4a4d-ba35-aa2404a57ebb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>scenario</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2699</th>\n","      <td>1</td>\n","      <td>I agreed to babysit for my neighbors tonight, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2700</th>\n","      <td>1</td>\n","      <td>I am justified in expecting my boss to give me...</td>\n","    </tr>\n","    <tr>\n","      <th>2701</th>\n","      <td>0</td>\n","      <td>I am justified in expecting my boss to give me...</td>\n","    </tr>\n","    <tr>\n","      <th>2702</th>\n","      <td>1</td>\n","      <td>I am justified in expecting my boss to give me...</td>\n","    </tr>\n","    <tr>\n","      <th>2703</th>\n","      <td>0</td>\n","      <td>I am justified in expecting my boss to give me...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab86ca53-e0cf-4a4d-ba35-aa2404a57ebb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ab86ca53-e0cf-4a4d-ba35-aa2404a57ebb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ab86ca53-e0cf-4a4d-ba35-aa2404a57ebb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["### BERT"],"metadata":{"id":"dB6_xNUv8Yoo"}},{"cell_type":"code","source":["!pip3 install adamp\n","!pip install torch_optimizer\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MUlzJK-C8y5O","executionInfo":{"status":"ok","timestamp":1688873783834,"user_tz":-540,"elapsed":29249,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"827b0891-7bc5-48f7-9254-a4d5b3486aeb"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting adamp\n","  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: adamp\n","  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5980 sha256=8d718d3844d8cb106dc20ba9b146a19ab408d45c5acc4abf91003cc995a74844\n","  Stored in directory: /root/.cache/pip/wheels/c7/ad/0f/b41b1c45b18c66e5eef5d2254415af8055c7e2b0934145157d\n","Successfully built adamp\n","Installing collected packages: adamp\n","Successfully installed adamp-0.3.0\n","Collecting torch_optimizer\n","  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (2.0.1+cu118)\n","Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)\n","  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.12.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (4.6.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torch_optimizer) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.5.0->torch_optimizer) (16.0.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)\n","Installing collected packages: pytorch-ranger, torch_optimizer\n","Successfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n","Collecting transformers\n","  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m63.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.utils import pad_sequences\n","from sklearn.model_selection import train_test_split\n","from adamp import AdamP\n","import torch_optimizer as optim\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","from transformers import TrainingArguments, Trainer\n","from transformers import EarlyStoppingCallback\n","\n","\n","import torch\n","import random\n","import time\n","import datetime"],"metadata":{"id":"wMBvDF5X8iIW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"598pNtFj20ya"},"source":["### GPU 확인"]},{"cell_type":"code","source":["n_devices = torch.cuda.device_count()\n","print(n_devices)\n","\n","for i in range(n_devices):\n","    print(torch.cuda.get_device_name(i))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ko6i3xzd9ipM","executionInfo":{"status":"ok","timestamp":1688682046910,"user_tz":-540,"elapsed":11,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"9bba6363-ec16-4e40-f64e-085ceb300e0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","Tesla T4\n"]}]},{"cell_type":"code","source":["print(train.shape)\n","print(test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAu6uecV9lLj","executionInfo":{"status":"ok","timestamp":1688682048899,"user_tz":-540,"elapsed":9,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"b1eabff3-46cf-4942-d747-867fa3960bcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(21791, 2)\n","(2704, 2)\n"]}]},{"cell_type":"markdown","source":["### Input Format 전처리\n","[CLS] : 모든 문장의 시작을 알리는 토큰\n","\n","[SEP] : 두 문장을 구분해주기 위한 토큰\n","\n"],"metadata":{"id":"TTKQA6yi9nu4"}},{"cell_type":"code","source":["bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in train['scenario']]\n","bert_sentences[:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"38qx4hEq9uEz","executionInfo":{"status":"ok","timestamp":1688682052399,"user_tz":-540,"elapsed":11,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"78f79ddf-54fe-4c7f-8a28-4f821986c801"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] I deserve to be paid by my boss because I keep her house clean daily. [SEP]',\n"," '[CLS] I deserve to be given a brand new car by my boss because I keep her house clean daily. [SEP]']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# 0'과 '1'의 재판 결과 라벨 컬럼 저장\n","\n","labels = train['label'].values\n","labels\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OHQvzUL91jn","executionInfo":{"status":"ok","timestamp":1688682054835,"user_tz":-540,"elapsed":5,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"3206ed4a-9cb8-4859-b332-46821819bede"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 1, 1])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["### Tokenization"],"metadata":{"id":"PIskj0PM-Agg"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in bert_sentences]\n","print(bert_sentences[0])\n","print(tokenized_texts[0])\n","print('tokenized_texts size : ',len(tokenized_texts))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":167,"referenced_widgets":["8a3755e77faf4b97bff01411ac9ed701","e9023d4922b449c7add5a9ad69d561a9","3e0ea3432c2e4183852bc781d394b6ce","acf8eb65f45a471d8ed0b2a8a6394f6d","4cdd5c78b4a548febd1dd733fdca6efd","3ecd3579910344d09f4829ecf70404ff","9ee3c21c086b4534b38cb47a9544da28","11424579fe194f21b823d52391e8c2f4","773f1631ebc943619a3bea54c93834e6","669ede875bd744b8b050d74bb3001a49","db31f43b356e43268d0650de6084d2ab","2d64cf1cc8b7449587b8f2ce5bad10a0","64239de487ca4cb0870bfd7408803d20","93b7350c32de445686ba5120ac11404e","0a026d7f0fc548bca2b18952821cadbd","63c3a22a2900480694e2a584fccbfffe","063d905e278c456282d67d0c95fc580b","b58c3725634648388a730b3932b8a405","7b7bae47e87446ffaf46b525fd95836a","07f12da275404a0d86fd07dbaf1d5c77","3ab811aa7eff47878e190de188d2f8f1","52bfd70c8a834d3c8fd03b598261619d","61c6e0be86b544dfa04c12d784a3b6e1","c5b5f4d111d8482b99913192896660e6","658108f7733a4482ac296497a31dd33b","a9f1d5f2ad1e4160bdef54cd7f1011ae","dcf391f8807d42aba093d0d2da6332a2","08924948bf95495d998a47d8689087a4","24865d07f9174d6382ab9847df1758eb","83c2239996c04a4f8675b62e35a75cab","6c10e4f347ec4de2bc817db059a92ad3","be8d0040268c40438694b5570ae22b9a","b6fcd43932774c5792a47a7729490695"]},"id":"uZZOzWCV-ENP","executionInfo":{"status":"ok","timestamp":1688682062191,"user_tz":-540,"elapsed":6566,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"b2e8aa56-2414-4088-86b0-45ee1bbb5f3a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a3755e77faf4b97bff01411ac9ed701"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d64cf1cc8b7449587b8f2ce5bad10a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61c6e0be86b544dfa04c12d784a3b6e1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[CLS] I deserve to be paid by my boss because I keep her house clean daily. [SEP]\n","['[CLS]', 'I', 'deserve', 'to', 'be', 'paid', 'by', 'my', 'boss', 'because', 'I', 'keep', 'her', 'house', 'clean', 'daily', '.', '[SEP]']\n","tokenized_texts size :  21791\n"]}]},{"cell_type":"markdown","source":["### Padding\n","token들의 max length보다 크게 MAX_LEN을 설정합니다.\n","\n","설정한 MAX_LEN 만큼 빈 공간을 0이 채웁니다.\n","\n","이 이후에, 문장의 최대 시퀀스를 설정하여 정수 인코딩과 제로 패딩을 수행해준다."],"metadata":{"id":"LXXChmL9-Gm_"}},{"cell_type":"code","source":["#token의 max length 찾기\n","len_list = [ len(token) for idx, token in enumerate(tokenized_texts)]\n","print(f'최대 시퀀스 : {max(len_list)}')  # 96"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSKU9ulk-O88","executionInfo":{"status":"ok","timestamp":1688682062194,"user_tz":-540,"elapsed":22,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"9fb6f616-fa0a-4af2-d569-9eb25d25adac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["최대 시퀀스 : 96\n"]}]},{"cell_type":"code","source":["MAX_LEN = 128 #최대 시퀀스 길이 설정\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","print(tokenized_texts[0])\n","print(input_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JoTZtcrA-euj","executionInfo":{"status":"ok","timestamp":1688682063224,"user_tz":-540,"elapsed":1047,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"8857a6b8-1bad-4c91-c08c-d128044af0bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['[CLS]', 'I', 'deserve', 'to', 'be', 'paid', 'by', 'my', 'boss', 'because', 'I', 'keep', 'her', 'house', 'clean', 'daily', '.', '[SEP]']\n","[  101   146 10026  1106  1129  3004  1118  1139  6054  1272   146  1712\n","  1123  1402  4044  3828   119   102     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0     0     0     0     0\n","     0     0     0     0     0     0     0     0]\n"]}]},{"cell_type":"markdown","source":["### 어텐션 마스크\n","\n","패딩된 값은 '0', 패딩되지 않은 단어는 '1'의 값을 갖는다"],"metadata":{"id":"yvfDoJSw-4mc"}},{"cell_type":"code","source":["attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","attention_masks[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLoATAM3_Dbm","executionInfo":{"status":"ok","timestamp":1688682064245,"user_tz":-540,"elapsed":1049,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"fd3ca2e9-f1a4-4e0b-97f4-24c54294fa62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 1.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0,\n"," 0.0]"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["### Train, Validation 데이터 분리\n","\n","\n","어텐션 마스크도 함께 훈련셋과 검증셋으로 분리하고, 데이터를 모두 파이토치 텐서로 변환시킨다"],"metadata":{"id":"RjL26jwV_Eir"}},{"cell_type":"code","source":["train_X, val_X, train_y, val_y = train_test_split(input_ids, labels,random_state=42,test_size=0.2)\n","\n","train_masks, val_masks, _, _ = train_test_split(attention_masks,\n","                                                       input_ids,\n","                                                       random_state=42,\n","                                                       test_size=0.2)\n","\n","# 파이토치 텐서로 변환\n","train_inputs = torch.tensor(train_X)\n","train_labels = torch.tensor(train_y)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(val_X)\n","validation_labels = torch.tensor(val_y)\n","validation_masks = torch.tensor(val_masks)"],"metadata":{"id":"oj3H5-wl_OFm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dy7GzSl48PuU"},"source":["\n","#### 데이터로더 설정\n","입력데이터, 어텐션 마스크, 라벨을 하나의 데이터로 묶어 train_dataloader, validation_dataloader라는 입력데이터를 생성"]},{"cell_type":"code","source":["learning_rate = 2e-5\n","epochs = 5\n","weight_decay = 1e-2\n","batch_size = 12\n","seed = 42"],"metadata":{"id":"TIxWgDDg_eQc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels ):\n","  train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","  train_sampler = RandomSampler(train_data)\n","  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","  validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","  validation_sampler = SequentialSampler(validation_data)\n","  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","  return train_dataloader, validation_dataloader\n","\n","\n","batch_size = batch_size\n","train_dataloader, validation_dataloader =  get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels )\n"],"metadata":{"id":"F7d5HqIq_9xV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NPEfQsgW8gNX"},"source":["### 테스트셋 전처리\n","Train 데이터와 동일하게 전처리해준다"]},{"cell_type":"code","source":["# [CLS] + 문장 + [SEP]\n","bert_sentences = [\"[CLS] \" + str(s) + \" [SEP]\" for s in test.scenario]\n","\n","\n","# Word 토크나이저 토큰화\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n","tokenized_texts_test = [tokenizer.tokenize(sent) for sent in bert_sentences]\n","\n","print('tokenized_texts_test size : ',len(tokenized_texts_test))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ph94NkC3AEE-","executionInfo":{"status":"ok","timestamp":1688682076073,"user_tz":-540,"elapsed":936,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"5669beea-fe1c-4859-c6c4-60c17670df18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tokenized_texts_test size :  2704\n"]}]},{"cell_type":"code","source":["# 시퀀스 설정 및 패딩\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts_test]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","\n","# 라벨 데이터\n","test_labels = test['label'].values\n","\n","# 어텐션 마스크\n","attention_masks = []\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","\n","\n","# 파이토치 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(test_labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","\n","# 배치 사이즈 설정 및 데이터 설정\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"metadata":{"id":"hwuuIr6AAVp-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KlBwmjmZEkxx"},"source":["### 모델 학습"]},{"cell_type":"code","source":["# GPU 설정\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-5gkYvsRAeos","executionInfo":{"status":"ok","timestamp":1688682081115,"user_tz":-540,"elapsed":36,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"59a917cc-72eb-4f82-d6a6-32da75915b46"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}]},{"cell_type":"markdown","metadata":{"id":"rGBYuitkmYJL"},"source":["### BERT 모델 생성"]},{"cell_type":"code","source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2 , output_attentions = False, output_hidden_states = False,) # 이진분류\n","model.cuda()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":977,"referenced_widgets":["119659ce539d4d2fb85b40321d844970","2b4ba5b1b6934a89a9785854aca6330c","7d36b2aba59e48d0b366d782738a0004","0a71a3c27503445288e2998cc4cff252","49adfbbf6e3740aa946ef498bbbc109c","19cc33e0254643dbb040289695fb83a2","71724af2d96e486d9dea0db4ff985e39","511d0336afcc4612ab5ba9abefdbc64d","14245042a5b846248e436b2457c83dec","993ba8d5df684a76b77639c90fc12a5a","ebc9fa1ac3424ffc8af1e23b4fd75383"]},"id":"rROn8KakAjzU","executionInfo":{"status":"ok","timestamp":1688682093338,"user_tz":-540,"elapsed":7965,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"6f818d90-7490-4b33-b005-8916e6910ce9"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"119659ce539d4d2fb85b40321d844970"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"YT4cImG5mpEZ"},"source":["#### 옵티마이저, 스케줄러 설정\n","\n","- AdamW\n","- AdamP\n","- RAdam\n"]},{"cell_type":"code","source":["# 옵티마이저\n","optimizer_AdamW = AdamW(model.parameters(),\n","                  lr = learning_rate, # 학습률(learning rate)\n","                  eps = 1e-8,\n","                  weight_decay=weight_decay  # 가중치 감쇠(L2 정규화)\n","                )\n","optimizer_AdamP = AdamP(model.parameters(),\n","                  lr = learning_rate, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=weight_decay,\n","                  eps = 1e-8\n","                )\n","\n","optimizer_RAdam = optim.RAdam(model.parameters(),\n","                  lr = learning_rate, # 학습률(learning rate)\n","                  betas=(0.9, 0.999),\n","                  weight_decay=weight_decay,\n","                  eps = 1e-8,\n","                )\n","\n","\n","\n","epochs =  epochs\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","# 스케줄러 생성 : Learning rate decay\n","scheduler_AdamW = get_linear_schedule_with_warmup(optimizer_AdamW,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","scheduler_AdamP = get_linear_schedule_with_warmup(optimizer_AdamP,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","scheduler_RAdam = get_linear_schedule_with_warmup(optimizer_RAdam,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n"],"metadata":{"id":"-j_j93vYArac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정확도 계산 함수\n","def accuracy_measure(preds, labels):\n","\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","# 시간 표시 함수\n","def time_elapsed(elapsed):\n","\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"metadata":{"id":"A-1cM9kmA6H4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_tp(preds, labels):\n","  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n","  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def calc_fp(preds, labels):\n","  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n","  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n","\n","def calc_tn(preds, labels):\n","  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n","  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def calc_fn(preds, labels):\n","  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n","  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n","\n","def get_metrics(preds, labels):\n","  '''\n","  Returns the following metrics:\n","    - accuracy    = (TP + TN) / N\n","    - precision   = TP / (TP + FP)\n","    - recall      = TP / (TP + FN)\n","    - specificity = TN / (TN + FP)\n","  '''\n","  preds = np.argmax(preds, axis = 1).flatten()\n","  labels = labels.flatten()\n","  tp = calc_tp(preds, labels)\n","  tn = calc_tn(preds, labels)\n","  fp = calc_fp(preds, labels)\n","  fn = calc_fn(preds, labels)\n","  b_accuracy = (tp + tn) / len(labels)\n","  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n","  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n","  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n","  if b_precision != 'nan' and b_recall != 'nan':\n","        b_f1 = 2*((b_precision*b_recall)/(b_precision+b_recall))\n","  else :\n","        b_f1 = 'nan'\n","\n","  return b_accuracy, b_precision, b_recall, b_specificity,  b_f1"],"metadata":{"id":"ll8xoDh7BQMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 모델 훈련"],"metadata":{"id":"yMuWasolFrM7"}},{"cell_type":"code","source":["def model_train(model_case, optimizer, scheduler, train_dataloader, validation_dataloader):\n","  #랜덤시드 고정\n","  seed_val = seed\n","  random.seed(seed_val)\n","  np.random.seed(seed_val)\n","  torch.manual_seed(seed_val)\n","  torch.cuda.manual_seed_all(seed_val)\n","\n","  #그래디언트 초기화\n","  model.zero_grad()\n","\n","  # 학습\n","  for epoch_i in range(0, epochs):\n","\n","      print(\"\")\n","      print('======== Train Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","      print('Training...')\n","\n","      # 시작 시간 설정\n","      t0 = time.time()\n","\n","      total_loss = 0\n","\n","      # 훈련모드로 변경\n","      model.train()\n","\n","      # 데이터로더에서 배치만큼 반복하여 가져옴\n","      for step, batch in enumerate(train_dataloader):\n","          # 경과 정보 표시\n","          if step % 300 == 0 and not step == 0:\n","              elapsed = time_elapsed(time.time() - t0)\n","              print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","          # 배치를 GPU에 넣음\n","          batch = tuple(t.to(device) for t in batch)\n","\n","          # 배치에서 데이터 추출\n","          b_input_ids, b_input_mask, b_labels = batch\n","\n","          # Forward 수행\n","          outputs = model(b_input_ids,\n","                          token_type_ids=None,\n","                          attention_mask=b_input_mask,\n","                          labels=b_labels)\n","\n","          # 로스 구함\n","          loss = outputs[0]\n","\n","          # 총 로스 계산\n","          total_loss += loss.item()\n","\n","          # Backward 수행으로 그래디언트 계산\n","          loss.backward()\n","\n","          # 그래디언트 클리핑\n","          torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","          # 그래디언트를 통해 가중치 파라미터 업데이트\n","          optimizer.step()\n","\n","          # 스케줄러로 학습률 감소\n","          scheduler.step()\n","\n","          # 그래디언트 초기화\n","          model.zero_grad()\n","\n","      # 평균 loss 계산\n","      avg_train_loss = total_loss / len(train_dataloader)\n","\n","      print(\"\")\n","      print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","      print(\"  Training epcoh took: {:}\".format(time_elapsed(time.time() - t0)))\n","\n","\n","\n","      print()\n","      print(\"Validation...\")\n","\n","      #시작 시간 설정\n","      t0 = time.time()\n","\n","      # 평가모드로 변경\n","      model.eval()\n","\n","      # 변수 초기화\n","      eval_loss, eval_accuracy = 0, 0\n","      nb_eval_steps, nb_eval_examples = 0, 0\n","\n","       # Tracking variables\n","      val_accuracy = []\n","      val_precision = []\n","      val_recall = []\n","      val_specificity = []\n","      val_f1 = []\n","\n","\n","      # 데이터로더에서 배치만큼 반복하여 가져옴\n","      for batch in validation_dataloader:\n","          # 배치를 GPU에 넣음\n","          batch = tuple(t.to(device) for t in batch)\n","\n","          # 배치에서 데이터 추출\n","          b_input_ids, b_input_mask, b_labels = batch\n","          # 그래디언트 계산 안함\n","          with torch.no_grad():\n","              # Forward 수행\n","              outputs = model(b_input_ids,\n","                              token_type_ids=None,\n","                              attention_mask=b_input_mask)\n","\n","          # 로스 구함\n","          logits = outputs[0]\n","\n","          # CPU로 데이터 이동\n","          logits = logits.detach().cpu().numpy()\n","          label_ids = b_labels.to('cpu').numpy()\n","\n","          # 출력 로짓과 라벨을 비교하여 정확도 계산\n","          tmp_eval_accuracy = accuracy_measure(logits, label_ids)\n","          eval_accuracy += tmp_eval_accuracy\n","          nb_eval_steps += 1\n","\n","          b_accuracy, b_precision, b_recall, b_specificity, b_f1 = get_metrics(logits, label_ids)\n","          val_accuracy.append(b_accuracy)\n","          # Update precision only when (tp + fp) !=0; ignore nan\n","          if b_precision != 'nan': val_precision.append(b_precision)\n","          # Update recall only when (tp + fn) !=0; ignore nan\n","          if b_recall != 'nan': val_recall.append(b_recall)\n","          # Update specificity only when (tn + fp) !=0; ignore nan\n","          if b_specificity != 'nan': val_specificity.append(b_specificity)\n","           # Update specificity only when (tn + fp) !=0; ignore nan\n","          if b_f1 != 'nan': val_f1.append(b_f1)\n","\n","\n","\n","      print(\"  Validation took: {:}\".format(time_elapsed(time.time() - t0)))\n","\n","      print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n","      print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n","      print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n","      print('\\t - Validation Specificity: {:.4f}'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n","      print('\\t - Validation F1: {:.4f}\\n'.format(sum(val_f1)/len(val_f1)) if len( val_f1)>0  else'\\t - Validation F1: NaN')\n","\n","\n","\n","\n","  print()\n","  print(\"======== COMPLETE ========\")\n","\n"],"metadata":{"id":"JvVtw56nBTnX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 옵티마이저 별 훈련\n","\n","- AdamW (가장 높은 성능을 보임)\n","\n","      - Validation Accuracy: 0.8310\n","      - Validation Precision: 0.8266\n","      - Validation Recall: 0.8695\n","      - Validation Specificity: 0.7870\n","      - Validation F1: 0.8370\n","\n","- AdamP\n","       - Validation Accuracy: 0.8226\n","       - Validation Precision: 0.8159\n","       - Validation Recall: 0.8667\n","       - Validation Specificity: 0.7720\n","       - Validation F1: 0.8307\n","\n","- RAdam\n","\n","      - Validation Accuracy: 0.8226\n","      - Validation Precision: 0.8159\n","      - Validation Recall: 0.8667\n","      - Validation Specificity: 0.7720\n","      - Validation F1: 0.8307"],"metadata":{"id":"1NmS9lipFiXz"}},{"cell_type":"code","source":["model_train('optimizer_AdamW', optimizer_AdamW, scheduler_AdamW,  train_dataloader, validation_dataloader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mupAub-nBpAz","executionInfo":{"status":"ok","timestamp":1688646149222,"user_tz":-540,"elapsed":2124494,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"2b90c214-18c0-4827-ca10-9eba14eb797f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","  Batch   500  of  1,453.    Elapsed: 0:02:10.\n","  Batch 1,000  of  1,453.    Elapsed: 0:04:25.\n","\n","  Average training loss: 0.50\n","  Training epcoh took: 0:06:27\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.7882\n","\t - Validation Precision: 0.7384\n","\t - Validation Recall: 0.9337\n","\t - Validation Specificity: 0.6118\n","\t - Validation F1: 0.8152\n","\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","  Batch   500  of  1,453.    Elapsed: 0:02:15.\n","  Batch 1,000  of  1,453.    Elapsed: 0:04:30.\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8114\n","\t - Validation Precision: 0.7927\n","\t - Validation Recall: 0.8835\n","\t - Validation Specificity: 0.7261\n","\t - Validation F1: 0.8242\n","\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","  Batch   500  of  1,453.    Elapsed: 0:02:16.\n","  Batch 1,000  of  1,453.    Elapsed: 0:04:34.\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:06:37\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8178\n","\t - Validation Precision: 0.7987\n","\t - Validation Recall: 0.8871\n","\t - Validation Specificity: 0.7379\n","\t - Validation F1: 0.8301\n","\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","  Batch   500  of  1,453.    Elapsed: 0:02:15.\n","  Batch 1,000  of  1,453.    Elapsed: 0:04:30.\n","\n","  Average training loss: 0.12\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8304\n","\t - Validation Precision: 0.8332\n","\t - Validation Recall: 0.8569\n","\t - Validation Specificity: 0.8026\n","\t - Validation F1: 0.8340\n","\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","  Batch   500  of  1,453.    Elapsed: 0:02:15.\n","  Batch 1,000  of  1,453.    Elapsed: 0:04:29.\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8310\n","\t - Validation Precision: 0.8266\n","\t - Validation Recall: 0.8695\n","\t - Validation Specificity: 0.7870\n","\t - Validation F1: 0.8370\n","\n","\n","======== COMPLETE ========\n"]}]},{"cell_type":"code","source":["model_train('optimizer_AdamP', optimizer_AdamP, scheduler_AdamP,  train_dataloader, validation_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49kzfqJhBvB-","executionInfo":{"status":"ok","timestamp":1688649467948,"user_tz":-540,"elapsed":2738369,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"c71d1057-33cf-42a5-d61b-02fd5cba5750"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:48.\n","  Batch   600  of  1,453.    Elapsed: 0:03:34.\n","  Batch   900  of  1,453.    Elapsed: 0:05:20.\n","  Batch 1,200  of  1,453.    Elapsed: 0:07:06.\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:08:35\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8175\n","\t - Validation Precision: 0.8318\n","\t - Validation Recall: 0.8316\n","\t - Validation Specificity: 0.8030\n","\t - Validation F1: 0.8205\n","\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:46.\n","  Batch   600  of  1,453.    Elapsed: 0:03:33.\n","  Batch   900  of  1,453.    Elapsed: 0:05:19.\n","  Batch 1,200  of  1,453.    Elapsed: 0:07:05.\n","\n","  Average training loss: 0.07\n","  Training epcoh took: 0:08:35\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8116\n","\t - Validation Precision: 0.8193\n","\t - Validation Recall: 0.8369\n","\t - Validation Specificity: 0.7818\n","\t - Validation F1: 0.8170\n","\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:46.\n","  Batch   600  of  1,453.    Elapsed: 0:03:32.\n","  Batch   900  of  1,453.    Elapsed: 0:05:19.\n","  Batch 1,200  of  1,453.    Elapsed: 0:07:05.\n","\n","  Average training loss: 0.06\n","  Training epcoh took: 0:08:34\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8148\n","\t - Validation Precision: 0.7942\n","\t - Validation Recall: 0.8836\n","\t - Validation Specificity: 0.7341\n","\t - Validation F1: 0.8263\n","\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:46.\n","  Batch   600  of  1,453.    Elapsed: 0:03:32.\n","  Batch   900  of  1,453.    Elapsed: 0:05:19.\n","  Batch 1,200  of  1,453.    Elapsed: 0:07:05.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:08:35\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8258\n","\t - Validation Precision: 0.8231\n","\t - Validation Recall: 0.8626\n","\t - Validation Specificity: 0.7810\n","\t - Validation F1: 0.8325\n","\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:46.\n","  Batch   600  of  1,453.    Elapsed: 0:03:33.\n","  Batch   900  of  1,453.    Elapsed: 0:05:19.\n","  Batch 1,200  of  1,453.    Elapsed: 0:07:05.\n","\n","  Average training loss: 0.02\n","  Training epcoh took: 0:08:34\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8226\n","\t - Validation Precision: 0.8159\n","\t - Validation Recall: 0.8667\n","\t - Validation Specificity: 0.7720\n","\t - Validation F1: 0.8307\n","\n","\n","======== COMPLETE ========\n"]}]},{"cell_type":"code","source":["model_train('optimizer_RAdam', optimizer_RAdam, scheduler_RAdam,  train_dataloader, validation_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vtfmiTPFEG2c","executionInfo":{"status":"ok","timestamp":1688651787076,"user_tz":-540,"elapsed":2131193,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"8b361aeb-447c-475d-f362-4bdca03c0264"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:22.\n","  Batch   600  of  1,453.    Elapsed: 0:02:43.\n","  Batch   900  of  1,453.    Elapsed: 0:04:05.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:26.\n","\n","  Average training loss: 0.02\n","  Training epcoh took: 0:06:34\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8171\n","\t - Validation Precision: 0.8409\n","\t - Validation Recall: 0.8176\n","\t - Validation Specificity: 0.8119\n","\t - Validation F1: 0.8181\n","\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:04.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:25.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:06:33\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8182\n","\t - Validation Precision: 0.8296\n","\t - Validation Recall: 0.8346\n","\t - Validation Specificity: 0.7987\n","\t - Validation F1: 0.8200\n","\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:25.\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:06:33\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8207\n","\t - Validation Precision: 0.8125\n","\t - Validation Recall: 0.8692\n","\t - Validation Specificity: 0.7633\n","\t - Validation F1: 0.8294\n","\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:25.\n","\n","  Average training loss: 0.02\n","  Training epcoh took: 0:06:33\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8159\n","\t - Validation Precision: 0.8091\n","\t - Validation Recall: 0.8629\n","\t - Validation Specificity: 0.7594\n","\t - Validation F1: 0.8242\n","\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:25.\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:06:33\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8201\n","\t - Validation Precision: 0.8128\n","\t - Validation Recall: 0.8706\n","\t - Validation Specificity: 0.7620\n","\t - Validation F1: 0.8292\n","\n","\n","======== COMPLETE ========\n"]}]},{"cell_type":"markdown","source":["#### earning rate 조정"],"metadata":{"id":"snYvWonAjMdK"}},{"cell_type":"code","source":["ptimizer_AdamW = AdamW(model.parameters(),\n","                  lr = 1e-5, # 학습률(learning rate)\n","                  eps = 1e-8,\n","                  weight_decay=weight_decay  # 가중치 감쇠(L2 정규화)\n","                )\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_AdamW = get_linear_schedule_with_warmup(optimizer_AdamW,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train('optimizer_AdamW', optimizer_AdamW, scheduler_AdamW,  train_dataloader, validation_dataloader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mnl1uQACXOBD","executionInfo":{"status":"ok","timestamp":1688654999901,"user_tz":-540,"elapsed":2126795,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"53742b3f-ad0a-4296-d5cf-fd41ea63412f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:23.\n","  Batch   600  of  1,453.    Elapsed: 0:02:46.\n","  Batch   900  of  1,453.    Elapsed: 0:04:07.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:28.\n","\n","  Average training loss: 0.05\n","  Training epcoh took: 0:06:36\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8052\n","\t - Validation Precision: 0.7815\n","\t - Validation Recall: 0.8863\n","\t - Validation Specificity: 0.7093\n","\t - Validation F1: 0.8199\n","\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8191\n","\t - Validation Precision: 0.8076\n","\t - Validation Recall: 0.8729\n","\t - Validation Specificity: 0.7588\n","\t - Validation F1: 0.8287\n","\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:02.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8059\n","\t - Validation Precision: 0.7867\n","\t - Validation Recall: 0.8809\n","\t - Validation Specificity: 0.7178\n","\t - Validation F1: 0.8214\n","\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:24.\n","\n","  Average training loss: 0.02\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8157\n","\t - Validation Precision: 0.8023\n","\t - Validation Recall: 0.8726\n","\t - Validation Specificity: 0.7490\n","\t - Validation F1: 0.8262\n","\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8205\n","\t - Validation Precision: 0.8203\n","\t - Validation Recall: 0.8534\n","\t - Validation Specificity: 0.7833\n","\t - Validation F1: 0.8255\n","\n","\n","======== COMPLETE ========\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"P5AOWp2MjlYi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### epoche 증가"],"metadata":{"id":"Qs2eDCVOjmF5"}},{"cell_type":"code","source":["optimizer_AdamW = AdamW(model.parameters(),\n","                  lr = learning_rate, # 학습률(learning rate)\n","                  eps = 1e-8,\n","                  weight_decay=weight_decay  # 가중치 감쇠(L2 정규화)\n","                )\n","# 에폭수\n","epochs = 10 # 5->10\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_AdamW = get_linear_schedule_with_warmup(optimizer_AdamW,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train('optimizer_AdamW', optimizer_AdamW, scheduler_AdamW,  train_dataloader, validation_dataloader)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2294PSoTjSEP","executionInfo":{"status":"ok","timestamp":1688659245446,"user_tz":-540,"elapsed":4243948,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"404a7fa8-3ac7-48d0-dcf8-707e131f8f1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:02.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8171\n","\t - Validation Precision: 0.8462\n","\t - Validation Recall: 0.8128\n","\t - Validation Specificity: 0.8218\n","\t - Validation F1: 0.8159\n","\n","\n","======== Train Epoch 2 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8072\n","\t - Validation Precision: 0.7948\n","\t - Validation Recall: 0.8689\n","\t - Validation Specificity: 0.7347\n","\t - Validation F1: 0.8196\n","\n","\n","======== Train Epoch 3 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8125\n","\t - Validation Precision: 0.8006\n","\t - Validation Recall: 0.8711\n","\t - Validation Specificity: 0.7444\n","\t - Validation F1: 0.8240\n","\n","\n","======== Train Epoch 4 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:02.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.04\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8120\n","\t - Validation Precision: 0.8128\n","\t - Validation Recall: 0.8486\n","\t - Validation Specificity: 0.7706\n","\t - Validation F1: 0.8195\n","\n","\n","======== Train Epoch 5 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8210\n","\t - Validation Precision: 0.8397\n","\t - Validation Recall: 0.8323\n","\t - Validation Specificity: 0.8056\n","\t - Validation F1: 0.8229\n","\n","\n","======== Train Epoch 6 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.03\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8212\n","\t - Validation Precision: 0.8248\n","\t - Validation Recall: 0.8538\n","\t - Validation Specificity: 0.7845\n","\t - Validation F1: 0.8273\n","\n","\n","======== Train Epoch 7 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:41.\n","  Batch   900  of  1,453.    Elapsed: 0:04:02.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8168\n","\t - Validation Precision: 0.8084\n","\t - Validation Recall: 0.8654\n","\t - Validation Specificity: 0.7619\n","\t - Validation F1: 0.8249\n","\n","\n","======== Train Epoch 8 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:23.\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:06:31\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8201\n","\t - Validation Precision: 0.8159\n","\t - Validation Recall: 0.8644\n","\t - Validation Specificity: 0.7713\n","\t - Validation F1: 0.8282\n","\n","\n","======== Train Epoch 9 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:24.\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8205\n","\t - Validation Precision: 0.8156\n","\t - Validation Recall: 0.8661\n","\t - Validation Specificity: 0.7702\n","\t - Validation F1: 0.8291\n","\n","\n","======== Train Epoch 10 / 10 ========\n","Training...\n","  Batch   300  of  1,453.    Elapsed: 0:01:21.\n","  Batch   600  of  1,453.    Elapsed: 0:02:42.\n","  Batch   900  of  1,453.    Elapsed: 0:04:03.\n","  Batch 1,200  of  1,453.    Elapsed: 0:05:24.\n","\n","  Average training loss: 0.01\n","  Training epcoh took: 0:06:32\n","\n","Validation...\n","  Validation took: 0:00:33\n","\t - Validation Accuracy: 0.8221\n","\t - Validation Precision: 0.8145\n","\t - Validation Recall: 0.8717\n","\t - Validation Specificity: 0.7674\n","\t - Validation F1: 0.8312\n","\n","\n","======== COMPLETE ========\n"]}]},{"cell_type":"code","source":["batch_size = 32 # 12 -> 32\n","train_dataloader, validation_dataloader =  get_train_validation_dataloader(batch_size, train_inputs, train_masks, train_labels, validation_inputs, validation_masks, validation_labels )\n","\n","optimizer_AdamW = AdamW(model.parameters(),\n","                  lr = learning_rate, # 학습률(learning rate)\n","                  eps = 1e-8,\n","                  weight_decay=weight_decay  # 가중치 감쇠(L2 정규화)\n","                )\n","# 에폭수\n","epochs = 5\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","scheduler_AdamW = get_linear_schedule_with_warmup(optimizer_AdamW,\n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","\n","model_train('optimizer_AdamW', optimizer_AdamW, scheduler_AdamW,  train_dataloader, validation_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qR_KICqhpIgg","executionInfo":{"status":"ok","timestamp":1688683983369,"user_tz":-540,"elapsed":1843321,"user":{"displayName":"Yunyoung Jang","userId":"03748636018068817510"}},"outputId":"65a749ef-e168-4468-a817-a5aa47f19bb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======== Train Epoch 1 / 5 ========\n","Training...\n","  Batch   300  of    545.    Elapsed: 0:03:05.\n","\n","  Average training loss: 0.51\n","  Training epcoh took: 0:05:37\n","\n","Validation...\n","  Validation took: 0:00:30\n","\t - Validation Accuracy: 0.7902\n","\t - Validation Precision: 0.7551\n","\t - Validation Recall: 0.9100\n","\t - Validation Specificity: 0.6460\n","\t - Validation F1: 0.8217\n","\n","\n","======== Train Epoch 2 / 5 ========\n","Training...\n","  Batch   300  of    545.    Elapsed: 0:03:07.\n","\n","  Average training loss: 0.32\n","  Training epcoh took: 0:05:39\n","\n","Validation...\n","  Validation took: 0:00:30\n","\t - Validation Accuracy: 0.8101\n","\t - Validation Precision: 0.7864\n","\t - Validation Recall: 0.8943\n","\t - Validation Specificity: 0.7101\n","\t - Validation F1: 0.8330\n","\n","\n","======== Train Epoch 3 / 5 ========\n","Training...\n","  Batch   300  of    545.    Elapsed: 0:03:06.\n","\n","  Average training loss: 0.20\n","  Training epcoh took: 0:05:39\n","\n","Validation...\n","  Validation took: 0:00:30\n","\t - Validation Accuracy: 0.8109\n","\t - Validation Precision: 0.7871\n","\t - Validation Recall: 0.8940\n","\t - Validation Specificity: 0.7119\n","\t - Validation F1: 0.8332\n","\n","\n","======== Train Epoch 4 / 5 ========\n","Training...\n","  Batch   300  of    545.    Elapsed: 0:03:06.\n","\n","  Average training loss: 0.12\n","  Training epcoh took: 0:05:39\n","\n","Validation...\n","  Validation took: 0:00:30\n","\t - Validation Accuracy: 0.8158\n","\t - Validation Precision: 0.8112\n","\t - Validation Recall: 0.8617\n","\t - Validation Specificity: 0.7598\n","\t - Validation F1: 0.8315\n","\n","\n","======== Train Epoch 5 / 5 ========\n","Training...\n","  Batch   300  of    545.    Elapsed: 0:03:07.\n","\n","  Average training loss: 0.08\n","  Training epcoh took: 0:05:39\n","\n","Validation...\n","  Validation took: 0:00:30\n","\t - Validation Accuracy: 0.8121\n","\t - Validation Precision: 0.8036\n","\t - Validation Recall: 0.8678\n","\t - Validation Specificity: 0.7457\n","\t - Validation F1: 0.8300\n","\n","\n","======== COMPLETE ========\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jhEHkdYvSdpA"},"execution_count":null,"outputs":[]}]}
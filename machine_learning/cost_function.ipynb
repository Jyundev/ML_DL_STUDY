{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COST FUNCTION (에러 모델) 구해보기 \n",
    "<img src = 'https://dsm01pap005files.storage.live.com/y4m782BgN83KPsiL4-hRivmKT6xieWsmQqlkK5kFn7VIFEBT7h99wORSdJKFr8wvbU7JomNqWQvj5U1hCu9HioNqonjdL5y6knbZl_-GHBtLcVS6nM--2DALtuWZ3N3uCL-2DgY9Lm3Ske6mJ3XwDlrRou3zIksrH5VAuWGkZ-ssX5YO3k0z1JWS3KMuKRK_VuvVYdo6rW-dq4Mhwk_78gKzw?encodeFailures=1&width=905&height=415'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.poly1d([1,1])\n",
    "b = np.poly1d([1,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "1 x + 1\n",
      " \n",
      "1 x - 1\n"
     ]
    }
   ],
   "source": [
    "print(a) # x+1\n",
    "print(b) # x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2\n",
      "1 x - 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "poly1d([ 1,  0, -1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(a*b)\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    2\n",
      "38 x - 94 x + 62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "poly1d([ 38, -94,  62])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.poly1d([2,-1])**2 + np.poly1d([3, -5])**2 + np.poly1d([5, -6])**2)\n",
    "np.poly1d([2,-1])**2 + np.poly1d([3, -5])**2 + np.poly1d([5, -6])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ---------------------------------------- 0.0/5.7 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.1/5.7 MB 2.2 MB/s eta 0:00:03\n",
      "     - -------------------------------------- 0.2/5.7 MB 2.5 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.4/5.7 MB 2.2 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.4/5.7 MB 2.2 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 0.5/5.7 MB 2.2 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.6/5.7 MB 2.2 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 0.7/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 0.8/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 0.9/5.7 MB 2.0 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 0.9/5.7 MB 2.1 MB/s eta 0:00:03\n",
      "     ------- -------------------------------- 1.0/5.7 MB 1.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 1.2/5.7 MB 1.9 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 1.3/5.7 MB 2.0 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 1.4/5.7 MB 1.9 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 1.5/5.7 MB 2.0 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 1.6/5.7 MB 2.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 1.8/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 1.9/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 2.0/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 2.1/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 2.2/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 2.4/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 2.5/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 2.5/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 2.7/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 2.8/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 2.9/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 3.0/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 3.1/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.2/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 3.4/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 3.4/5.7 MB 2.2 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 3.6/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 3.6/5.7 MB 2.1 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 3.7/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 3.8/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 3.9/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.0/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.2/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 4.3/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.4/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.4/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.4/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.4/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 4.4/5.7 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.5/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 4.5/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 4.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 4.8/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 4.9/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 5.0/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.1/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.2/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.3/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 5.4/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 5.5/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.7/5.7 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.7/5.7 MB 1.9 MB/s eta 0:00:00\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ---------- --------------------------- 143.4/536.2 kB 2.9 MB/s eta 0:00:01\n",
      "     ------------------- ------------------ 276.5/536.2 kB 2.4 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 409.6/536.2 kB 2.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- -- 501.8/536.2 kB 2.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 536.2/536.2 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy\n",
      "Successfully installed mpmath-1.3.0 sympy-1.12\n"
     ]
    }
   ],
   "source": [
    "!pip install sympy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 76 \\theta - 94$"
      ],
      "text/plain": [
       "76*theta - 94"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sympy as sym\n",
    "\n",
    "theta = sym.Symbol('theta')\n",
    "diff_th = sym.diff( 38*theta**2 -94*theta +62, theta) #theta에 대한 미분을 수행하는 코드입니다.\n",
    "diff_th"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent & Learning Rate<p>\n",
    "<p>\n",
    "Gradient Descent(경사 하강법)은 함수의 최솟값을 찾기 위해 사용되는 최적화 알고리즘입니다.<p>\n",
    "이 알고리즘은 기울기(gradient)를 이용하여 함수의 최솟값을 찾아가는 방식으로 동작합니다. 기울기는 함수의 특정 점에서의 변화율을 나타내며, 최솟값은 기울기가 0인 지점입니다.<p>\n",
    "<p>\n",
    "초기 값 설정: 경사 하강법을 시작하기 위해 최적화하려는 함수와 시작 지점의 초기 값을 설정합니다.<p>\n",
    "<p>\n",
    "기울기 계산: 현재 위치에서 함수의 기울기(gradient)를 계산합니다. 이는 함수의 모든 독립 변수에 대한 편도함수를 계산하여 얻을 수 있습니다.<p>\n",
    "<p>\n",
    "갱신 규칙: 기울기의 방향으로 이동하여 함수 값을 감소시키기 위해 현재 위치를 갱신합니다. 이때 갱신하는 양은 학습률(learning rate)에 의해 결정됩니다.<p>\n",
    "<p>\n",
    "종료 조건 확인: 일정한 조건을 만족하는지 확인하여 알고리즘을 종료합니다. 종료 조건은 예를 들어 일정한 반복 횟수, 함수 값의 수렴 등을 확인할 수 있습니다.<p>\n",
    "<p>\n",
    "학습률(learning rate)은 경사 하강법에서 중요한 하이퍼파라미터입니다. 이 값은 갱신 규칙에서 현재 위치를 얼마나 크게 이동시킬지를 결정합니다. 너무 작은 학습률은 수렴 속도를 늦추고 최적점에 도달하는 데 오랜 시간이 걸릴 수 있습니다. 반면에 너무 큰 학습률은 발산하거나 최적점을 지나칠 수 있습니다.<p>\n",
    "\n",
    "<br>\n",
    "<img src ='https://static.javatpoint.com/tutorial/machine-learning/images/gradient-descent-in-machine-learning1.png' >\n",
    "\n",
    "[image : Gradient Descent in Machine Learning](https://www.javatpoint.com/gradient-descent-in-machine-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
